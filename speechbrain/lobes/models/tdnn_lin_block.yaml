block_index: 1
sequence: [linear1, norm1, activation1, linear2, norm2, activation2, linear3]

#linear1: !speechbrain.nnet.linear.Linear

linear1: !speechbrain.nnet.linear.Linear
    n_neurons: 512
    bias: True

norm1: !speechbrain.nnet.normalization.Normalize
    norm_type: batchnorm

activation1: !torch.nn.LeakyReLU

linear2: !speechbrain.nnet.linear.Linear
    n_neurons: 512
    bias: True

norm2: !speechbrain.nnet.normalization.Normalize
    norm_type: batchnorm

activation2: !torch.nn.LeakyReLU

linear3: !speechbrain.nnet.linear.Linear
    n_neurons: 2
    bias: True

# decide this after tunning
dropout: !speechbrain.nnet.dropout.Dropout
    drop_rate: 0.15
