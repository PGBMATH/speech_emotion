# ################################
# Model: ConvTasnet for source separation
# Data : Minimal Example
# Author: Cem Subakan
# ################################


# Basic parameters
# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 1234
__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]
use_tensorboard: False
tensorboard_logs: runs/minimal_example
output_folder: !ref results/conv_tasnet/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt
data_folder: !PLACEHOLDER
csv_tr: !ref <data_folder>/minimal_example_convtasnet_tr.csv
csv_cv: !ref <data_folder>/minimal_example_convtasnet_cv.csv
csv_tt: !ref <data_folder>/minimal_example_convtasnet_tt.csv

# Neural Parameters
N_epochs: 150
N_batch: 1
lr: 0.002
progressbar: True
loss_fn: 'sisnr'
train_onthefly: False

train_loader: !new:speechbrain.data_io.DataLoaderFactory
    csv_file: !ref <csv_tr>
    batch_size: !ref <N_batch>
    sentence_sorting: random
    csv_read: [mix_wav, s1_wav, s2_wav]
    replacements:
        $data_folder: !ref <data_folder>

val_loader: !new:speechbrain.data_io.DataLoaderFactory
    csv_file: !ref <csv_cv>
    batch_size: !ref <N_batch>
    sentence_sorting: random
    csv_read: [mix_wav, s1_wav, s2_wav]
    replacements:
        $data_folder: !ref <data_folder>

test_loader: !new:speechbrain.data_io.DataLoaderFactory
    csv_file: !ref <csv_tt>
    batch_size: !ref <N_batch>
    sentence_sorting: random
    csv_read: [mix_wav, s1_wav, s2_wav]
    replacements:
        $data_folder: !ref <data_folder>

mask_net: !new:speechbrain.lobes.models.conv_tasnet.MaskNet
    N: 32
    B: 32
    H: 32
    P: 3
    X: 1
    R: 2
    C: 2
    norm_type: 'gLN'
    causal: False
    mask_nonlinear: 'relu'

encoder: !new:speechbrain.lobes.models.conv_tasnet.Encoder
    L: 21
    N: 32

decoder: !new:speechbrain.lobes.models.conv_tasnet.Decoder
    L: 20
    N: 32

modules:
    mask_net: !ref <mask_net>
    encoder: !ref <encoder>
    decoder: !ref <decoder>

opt_class: !name:torch.optim.Adam
    lr: !ref <lr>

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <N_epochs>

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>
