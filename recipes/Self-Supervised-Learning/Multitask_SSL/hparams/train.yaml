# ################################
# Model: PASE with CRDNN encoder
# Authors : Salah Zaiem & Titouan Parcollet
# ################################

# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 2209
__set_seed: !!python/object/apply: torch.manual_seed [!ref < seed >]
output_folder: !ref results/multi_task_CRDNN_fr/<seed>
csv_folder: !PLACEHOLDER  # Folder containing the task labels, one csv_file per audio_sample
save_folder: !ref < output_folder >/workers_save
train_log: !ref < output_folder >/train_log.txt
# Data files
# root path of the commonvoice dataset, may be needed for the preparation
data_folder: !PLACEHOLDER
wav_folder: !PLACEHOLDER  #Path to the wav files, needed if the preparation has not been done
train_tsv_file: !ref < data_folder >/train.tsv  # Standard CommonVoice .tsv files
dev_tsv_file: !ref < data_folder >/dev.tsv  # Standard CommonVoice .tsv files
test_tsv_file: !ref < data_folder >/test.tsv  # Standard CommonVoice .tsv files
duration_threshold: 15  # Longer sentences will be removed (in seconds)
train_csv: !ref < csv_folder >/train.csv
valid_csv: !ref < csv_folder >/dev.csv
test_csv: !ref < csv_folder >/test.csv
#To be adapted to the datset
avoid_if_longer_than: 35
sorting: ascending
# Training parameters
number_of_epochs: 5
batch_size: 2
batch_counter: 0
lr: 1.0
device: 'cuda:0'
multigpu: True
ckpt_interval_minutes: 30
# Feature parameters
sample_rate: 16000
n_fft: 400
n_mels: 80
test_batch_size: 8
dataloader_options:
    batch_size: !ref < batch_size >
    num_workers: 8
test_dataloader_options:
    batch_size: !ref < test_batch_size >
    num_workers: 8
# Model parameters
activation: !name: torch.nn.LeakyReLU
dropout: 0.15
cnn_blocks: 3
cnn_channels: (128, 200, 256)
cnn_channels_dec: (256, 200, 128)
inter_layer_pooling_size: (2, 2, 2)
inter_layer_ps: (1, 1, 1)
cnn_kernelsize: (3, 3)
time_pooling_size: 1
rnn_class: !name: speechbrain.nnet.RNN.LSTM
rnn_layers: 5
rnn_neurons: 512
rnn_bidirectional: True
dnn_blocks: 2
dnn_neurons: 1024

# Workers
# To add workers, you have to add it here with the corresponding weight for the loss
# They have to match the name of the worker in the csv files containing the values
# An example is given with a possible pitch feature you may add
workers: [
    'melfs',
    'mfcc',
    #'pitch_feature'
    ]
#Online workers are workers whose labels are computed on the fly (spectrograms for instance)
online_workers: [
    'melfs',
    'mfcc',
    ]
#mel and mfccs are weighted with 1.
workers_weights: {"melfs":1.0 , "mfcc":1.0}
# Functions
enc: !new: speechbrain.lobes.models.CRDNN.CRDNN
    input_shape: [null, null, !ref < n_mels > ]
    activation: !ref < activation >
    dropout: !ref < dropout >
    cnn_blocks: !ref < cnn_blocks >
    cnn_channels: !ref < cnn_channels >
    cnn_kernelsize: !ref < cnn_kernelsize >
    inter_layer_pooling_size: !ref < inter_layer_pooling_size >
    time_pooling: True
    using_2d_pooling: False
    time_pooling_size: !ref < time_pooling_size >
    rnn_class: !ref < rnn_class >
    rnn_layers: !ref < rnn_layers >
    rnn_neurons: !ref < rnn_neurons >
    rnn_bidirectional: !ref < rnn_bidirectional >
    rnn_re_init: True
    dnn_blocks: !ref < dnn_blocks >
    dnn_neurons: !ref < dnn_neurons >

# Workers
# When adding new pretext tasks, you would have to add a new worker here
# You can follow the mel and mfcc workers examples
mel: !new: speechbrain.lobes.models.VanillaNN.VanillaNN
    input_shape: [null, null, !ref < dnn_neurons > ]
    dnn_neurons: !ref < n_mels >
mfcc: !new: speechbrain.lobes.models.VanillaNN.VanillaNN
    activation: !name: torch.nn.PReLU
    input_shape: [null, null, !ref < dnn_neurons > ]
    dnn_neurons: 60
#The following worker is an example for an added pretext task. 
pitch_feature: !new: speechbrain.lobes.models.VanillaNN.VanillaNN
    activation: !name: torch.nn.PReLU
    input_shape: [null, null, !ref < dnn_neurons > ]
    dnn_neurons: 1
normalize: !new: speechbrain.processing.features.InputNormalization
        norm_type: global
mfcc_normalizer: !new: speechbrain.processing.features.InputNormalization
        norm_type: sentence
classification_loss: !name: torch.nn.CrossEntropyLoss
reconstruction_loss: !name: torch.nn.MSELoss
regression_loss: !name: torch.nn.L1Loss
#Example of added loss
pitch_feature_loss: !name: torch.nn.MSELoss

workers_regressors: {
    "melfs": !ref < mel >,
    "mfcc": !ref < mfcc >
#"pitch_feature": !ref <pitch_feature>
}
# Same for the losses
workers_losses: {
    "melfs": !ref < reconstruction_loss >,
    "mfcc": !ref < hparams.reconstruction_loss>,
     #"pitch_feature": !ref <pitch_feature_loss>,
}

log_softmax: !new: speechbrain.nnet.activations.Softmax
        apply_log: True
opt_class: !name: torch.optim.Adadelta
        lr: !ref < lr >
        rho: 0.95
        eps: 1.e-8
modules:
    enc: !ref <enc>
    mel: !ref < mel >
    mfcc: !ref < mfcc >
    pitch_feature: !ref <pitch_feature>
model: !new: torch.nn.ModuleList
    - [!ref < enc > ,  !ref < mel > , !ref < mfcc > , !ref < pitch_feature> ]
checkpointer: !new: speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref < save_folder >
recoverables:
    model: !ref < model >
    scheduler: !ref < lr_annealing >
    normalizer: !ref < normalize >
    counter: !ref < epoch_counter >

lr_annealing: !new: speechbrain.nnet.schedulers.NewBobScheduler
    initial_value: !ref < lr >
    improvement_threshold: 0.0025
    annealing_factor: 0.75
    patient: 0
epoch_counter: !new: speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref < number_of_epochs >

MFCC_head: !new: speechbrain.lobes.features.MFCC
    sample_rate: !ref < sample_rate >
    n_fft: !ref <n_fft>
    n_mels: 40
   
compute_features: !new: speechbrain.lobes.features.Fbank
    sample_rate: !ref < sample_rate >
    n_fft: !ref <n_fft>
    n_mels: !ref < n_mels >
    train_logger: !new: speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref < train_log >

online_computation: { "melfs" : !ref < compute_features >, 
        "mfcc" : !ref < MFCC_head >}
online_normalization: { "melfs" : !ref < normalize >, 
        "mfcc" : !ref < mfcc_normalizer >}
