# Generated 2021-03-23 from:
# /home/alexr/speechbrain_tts/recipes/TTS/models/wavenet/hparams.yaml
# yamllint disable
seed: 42
__set_seed: !!python/object/apply:torch.manual_seed [42]

# 1. raw [-1, 1]
# 2. mulaw [-1, 1]
# 3. mulaw-quantize [0, mu]
# If input_type is raw or mulaw, network assumes scalar input and discretized mixture 
# of logistic distributions output, otherwise one-hot input and softmax output are assumed.
input_type: raw
quantize_channels: 65536  # 65536 or 256

# waveform global gain normalization scale
global_gain_scale: 0.55

sample_rate: 22050
silence_threshold: 2

# Model:
# This should equal to `quantize_channels` if mu-law quantize enabled
# otherwise num_mixture * 3 (pi, mean, log_scale)
# single mixture case: 2
num_mixture: 10
out_channels: 30
layers: 24
stacks: 4
residual_channels: 128
gate_channels: 256  # split into 2 gropus internally for gated activation
skip_out_channels: 128
dropout: 0.0
kernel_size: 3

# Local conditioning (set negative value to disable, e.g. -1))
cin_channels: -1 #80
cin_pad: 2
# If True, use transposed convolutions to upsample conditional features,
# otherwise repeat features to adjust time resolution
# (refer to section 2.5 in Wavenet paper)
upsample_conditional_features: true
upsample_scales: &id001 [4, 4, 4, 4]

# Global conditioning (set negative value to disable)
# currently limited for speaker embedding
# this should only be enabled for multi-speaker dataset
upsample_net: &id002 !new:models.wavenet.upsample.ConvInUpsampleNetwork
  upsample_scales: *id001
gin_channels: -1  # i.e., speaker embedding dim
n_speakers: 7  # 7 for CMU ARCTIC

lr: 0.0005
lr_warmup_steps: 4000
number_of_epochs: 2

causal: true

num_mels: 80
fmin: 125
fmax: 7600
fft_size: 1024
hop_size: 256
frame_shift_ms:
win_length: 1024
win_length_ms: -1.0
window: hann
highpass_cutoff: 70.0
output_distribution: Logistic
log_scale_min: -9.0

lr_schedule: step_learning_rate_decay
lr_schedule_kwargs:
- anneal_rate: 0.5
- anneal_interval: 200000

max_train_steps: 100
nepochs: 2000
clip_thresh: -1
max_time_sec:
max_time_steps: 2560
exponential_moving_average: true
ema_decay: 0.9999
checkpoint_interval: 50
train_eval_interval: 50
test_eval_epoch_interval: 1
save_optimizer_state: true

datasets:
  train:
    path: datasets/testdata/fake_vctk

model: &id003 !new:models.wavenet.model.WaveNet

  out_channels: 30
  layers: 24
  stacks: 4
  residual_channels: 128
  gate_channels: 256
  skip_out_channels: 128
  kernel_size: 3
  dropout: 0.0
  cin_channels: -1
  gin_channels: -1
  cin_pad: 2
  n_speakers: 7
  upsample_conditional_features: true
  upsample_net: *id002
  upsample_scales: *id001
  scalar_input: false
  use_speaker_embedding: false
  output_distribution: Logistic

modules:
  model: *id003
output_folder: ./results/tts/wavenet/42
save_folder: ./results/tts/wavenet/42/save
train_log: ./results/tts/wavenet/42/train_log.txt

epoch_counter: &id004 !new:speechbrain.utils.epoch_loop.EpochCounter

  limit: 2

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: ./results/tts/wavenet/42/save
  recoverables:
    model: *id003
    counter: *id004
pin_memory: true
num_workers: 0
batch_size: 1
opt_class: !name:torch.optim.Adam
  lr: 0.0005

dataloader_options:
  batch_size: 1
