seed: 42
__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]

embed_dim: 128
batch_size: 32
encoder_conv_channels: 256
n_vocab: 59
dropout: 0.1
mel_dim: 80
outputs_per_step: 1
downsample_step: 4
masked_loss_weight: 0.5
binary_divergence_weight: 0.1
priority_freq: 3000
priority_freq_weight: 0.0
sample_rate: 22050
encoder_in_std_mul: 1.0
encoder_mid_std_mul: 2.0
encoder_out_std_mul: 4.0
encoder_conv_kernel_size: 5
encoder_conv_dilation: 1
encoder_out_kernel_size: 1
preattention_out_channels: 256
preattention_conv_channels: 256
preattention_in_std_mul: 1.0
preattention_conv_std_mul: 2.0
decoder_in_dim: !ref <mel_dim>
decoder_conv_std_mul: 1.0
decoder_conv_channels: 256
decoder_query_position_rate: 1.0
decoder_key_position_rate: 1.29
decoder_max_positions: 1024
converter_conv_channels: 256
converter_conv_kernel_size: 5
converter_out_kernel_size: 1
converter_in_std_mul: 1.0
converter_mid_std_mul: 4.0
converter_out_std_mul: 4.0
converter_in_dim: !ref <decoder_conv_channels>
linear_dim: 513

lr: 0.0005
lr_warmup_steps: 4000
number_of_epochs: 2

output_folder: !ref ./results/tts/deepvoice/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt

encoder: !new:speechbrain.lobes.models.synthesis.deepvoice3.Encoder
  embed_dim: !ref <embed_dim>
  n_vocab: !ref <n_vocab>
  dropout: !ref <dropout>

  convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <embed_dim>
      out_channels: !ref <encoder_conv_channels>
      kernel_size: 5
      dilation: 1
      padding: same
      skip_transpose: True
      dropout: !ref <dropout>
      std_mul: !ref <encoder_in_std_mul>
    # - !new:speechbrain.lobes.models.synthesis.deepvoice3.WeightNorm
    #   inner: !new:speechbrain.nnet.CNN.Conv1d
    #     in_channels: !ref <embed_dim>
    #     out_channels: !ref <encoder_conv_channels>
    #     kernel_size: 5
    #     dilation: 1
    #     padding: same
    #     skip_transpose: True
    #   dropout: !ref <dropout>
    #   std_mul: !ref <encoder_in_std_mul>
    - !new:torch.nn.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &encoder_conv
      in_channels: !ref <encoder_conv_channels>
      out_channels: !ref 2 * <encoder_conv_channels>
      kernel_size: !ref <encoder_conv_kernel_size>
      dilation: !ref <encoder_conv_dilation>
      padding: same
      dropout: !ref <dropout>
      std_mul: !ref <encoder_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 9
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 27
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 9
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 27
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <encoder_conv_channels>
      out_channels: !ref <embed_dim>
      kernel_size: !ref <encoder_out_kernel_size>
      padding: valid
      dilation: !ref <encoder_conv_dilation>
      skip_transpose: True
      std_mul: !ref <encoder_out_std_mul>
      dropout: !ref <dropout>

    # - !new:speechbrain.lobes.models.synthesis.deepvoice3.WeightNorm
    #   inner: !new:speechbrain.nnet.CNN.Conv1d
    #     in_channels: !ref <encoder_conv_channels>
    #     out_channels: !ref <embed_dim>
    #     kernel_size: !ref <encoder_out_kernel_size>
    #     padding: valid
    #     dilation: !ref <encoder_conv_dilation>
    #     skip_transpose: True
    #   std_mul: !ref <encoder_out_std_mul>
    #   dropout: !ref <dropout>

decoder: !new:speechbrain.lobes.models.synthesis.deepvoice3.Decoder
    embed_dim: !ref <embed_dim>
    in_channels: !ref <decoder_conv_channels>
    preattention:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <decoder_in_dim>
      out_channels: !ref <preattention_conv_channels>
      kernel_size: 1
      dilation: 1
      skip_transpose: True
      padding: valid
      std_mul: !ref <preattention_in_std_mul>
      dropout: !ref <dropout>
    - !new:torch.nn.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &preattention_conv
      in_channels: !ref <preattention_conv_channels>
      out_channels: !ref 2 * <preattention_conv_channels>
      kernel_size: 1
      padding: valid
      dilation: 1
      causal: true
      residual: true
      std_mul: !ref <preattention_conv_std_mul>
      dropout: !ref <dropout>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *preattention_conv
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *preattention_conv
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *preattention_conv
    convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &decoder_conv
      in_channels: !ref <decoder_conv_channels>
      out_channels: !ref 2 * <decoder_conv_channels>
      kernel_size: 1
      padding: same
      dilation: 1
      std_mul: !ref <decoder_conv_std_mul>
      dropout: !ref <dropout>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_conv
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_conv
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_conv
    attention:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionLayer &decoder_attention
      conv_channels: !ref <preattention_out_channels>
      embed_dim: !ref <embed_dim>
      query_projection: !new:torch.nn.Linear
        in_features: !ref <preattention_out_channels>
        out_features: !ref <embed_dim>
      key_projection: !new:torch.nn.Identity
      value_projection: !new:torch.nn.Linear
        in_features: !ref <embed_dim>
        out_features: !ref <embed_dim>
      out_projection: !new:torch.nn.Linear
        in_features: !ref <embed_dim>
        out_features: !ref <preattention_out_channels>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionLayer
      <<: *decoder_attention
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionLayer
      <<: *decoder_attention
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionLayer
      <<: *decoder_attention

    output: !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <preattention_out_channels>
      out_channels: !ref <decoder_in_dim> * <outputs_per_step>
      kernel_size: 1
      dilation: 1
      padding: valid
      skip_transpose: True
      std_mul: !ref <preattention_in_std_mul>
      dropout: !ref <dropout>

    max_positions: !ref <decoder_max_positions>
    in_dim: !ref <decoder_in_dim>
    outputs_per_step: !ref <outputs_per_step>
    dropout: !ref <dropout>
    query_position_rate: !ref <decoder_query_position_rate>
    key_position_rate: !ref <decoder_key_position_rate>  


converter: !new:speechbrain.lobes.models.synthesis.deepvoice3.Converter
  in_dim: !ref <decoder_in_dim>
  out_dim: !ref <linear_dim>
  convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.WeightNorm
      inner: !new:speechbrain.nnet.CNN.Conv1d
        in_channels: !ref <converter_in_dim>
        out_channels: !ref <converter_conv_channels>
        kernel_size: !ref <converter_conv_kernel_size>
        dilation: 1
        skip_transpose: True
      std_mul: !ref <converter_in_std_mul>
      dropout: !ref <dropout>
    - !new:torch.nn.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &converter_conv
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref 2 * <converter_conv_channels>
      kernel_size: !ref <converter_conv_kernel_size>
      std_mul: !ref <converter_mid_std_mul>
      dilation: 1
      dropout: !ref <dropout>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock 
      <<: *converter_conv
      dilation: 3
      dropout: !ref <dropout>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      out_channels: !ref 2 * <converter_conv_channels>
      dilation: 1
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      in_channels: !ref  <converter_conv_channels>
      out_channels: !ref 2 * <converter_conv_channels>
      dilation: 3
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.WeightNorm
      inner: !new:speechbrain.nnet.CNN.Conv1d
        in_channels: !ref <converter_conv_channels>
        out_channels: !ref <linear_dim>
        kernel_size: !ref <converter_out_kernel_size>
        dilation: 1
        skip_transpose: True
      std_mul: !ref <converter_out_std_mul>
      dropout: !ref <dropout>

seq2seq: !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionSeq2Seq
  encoder: !ref <encoder>
  decoder: !ref <decoder>

model: !new:speechbrain.lobes.models.synthesis.deepvoice3.TTSModel
  seq2seq: !ref <seq2seq>
  mel_dim: !ref <mel_dim>
  linear_dim: !ref <linear_dim>
  postnet: !ref <converter>

compute_cost: !new:speechbrain.lobes.models.synthesis.deepvoice3.Loss
  linear_dim: !ref <linear_dim>
  downsample_step: !ref <downsample_step>
  outputs_per_step: !ref <outputs_per_step>
  masked_loss_weight: !ref <masked_loss_weight>
  binary_divergence_weight: !ref <binary_divergence_weight>
  priority_freq: !ref <priority_freq>
  priority_freq_weight: !ref <priority_freq_weight>
  sample_rate: !ref <sample_rate>

lr_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler
  lr_initial: !ref <lr>
  n_warmup_steps: !ref <lr_warmup_steps>

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <number_of_epochs>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <save_folder>
  recoverables:
    model: !ref <model>
    counter: !ref <epoch_counter>

modules:
  model: !ref <model>

datasets:
  train:
    path: ../datasets/testdata/fake_vctk

opt_class: !name:torch.optim.Adam
  lr: !ref <lr>

dataloader_options:
  batch_size: !ref <batch_size>

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>