# ################################
# Model: DeepVoice3 - Multispeaker
# Training
# Authors:
# * Artem Ploujnikov 2021
# ################################
seed: 72
__set_seed: !apply:torch.manual_seed [!ref <seed>]

embed_dim: 256
speaker_embed_dim: 16
batch_size: 32
use_speaker_embed: True
speaker_embedding_weight_std: 0.01
n_speakers: 108
n_vocab: 128
dropout: 0.05
mel_dim: 80
outputs_per_step: 1
downsample_step: 4
time_upsampling: !ref <downsample_step> // <outputs_per_step>
max_target_len: 1024
masked_loss_weight: 0.5
binary_divergence_weight: 0.1
priority_freq: 3000
priority_freq_weight: 0.0
source_sample_rate: 48000
sample_rate: 22050
trim_threshold: -30.
window_ahead: 3
window_backward: 1
encoder_in_std_mul: 1.0
encoder_mid_std_mul: 2.0
encoder_out_std_mul: 4.0
encoder_conv_kernel_size: 5
encoder_conv_channels: 128
encoder_conv_dilation: 1
encoder_out_kernel_size: 1
preattention_out_channels: 256
preattention_conv_channels: 256
preattention_conv_kernel_size: 5
preattention_in_std_mul: 1.0
preattention_mid_std_mul: 2.0
preattention_high_std_mul: 4.0
decoder_in_dim: !ref <mel_dim>
decoder_conv_std_mul: 1.0
decoder_conv_channels: 256
decoder_conv_kernel_size: 5
decoder_query_position_rate: 1.0
decoder_key_position_rate: 1.29
decoder_max_positions: 512
decoder_key_projection: True
decoder_value_projection: True
decoder_low_std_mul: 1.0
decoder_mid_std_mul: 4.0
decoder_high_std_mul: 4.0
converter_conv_channels: 256
converter_conv_channels_bottom: !ref 2 * <converter_conv_channels>
converter_conv_kernel_size: 5
converter_out_kernel_size: 1
converter_in_std_mul: 1.0
converter_mid_std_mul: 4.0
converter_out_std_mul: 4.0
converter_in_dim: !ref <decoder_conv_channels>
linear_dim: 513
n_fft: 1024
max_mel_len: !ref <decoder_max_positions> // <downsample_step>
max_input_len: 128
max_output_len: 512
hop_length: 256
mel_downsample_step: 4
min_level_db: -100
ref_level_db: 20
pad_linear: !ref <max_output_len>
pad_mel: !ref <max_mel_len>
guided_attention_sigma: 0.2
padding_idx: 0
embedding_weight_std: 0.1
force_monotonic_attention: True
use_decoder_state_for_postnet_input: True
freeze_embedding: False
lr: 0.0005
lr_warmup_steps: 4000
max_grad_norm: 0.1
number_of_epochs: 50
ckpt_frequency: 100
progress_samples: True
progress_samples_incremental: False
progress_sample_path: !ref <output_folder>/samples
progress_samples_interval: 100
overfit_test: False
overfit_test_iterations: 1
train_data_path: ../datasets/testdata/fake_vctk_1ex
valid_data_path: ../datasets/testdata/fake_vctk_1ex
save_for_pretrained: True
output_folder: !ref ./results/tts/deepvoice3/<seed>
save_folder: !ref <output_folder>/save
pretrained_path: !ref <save_folder>
train_log: !ref <output_folder>/train_log.txt
tensorboard_logs: !ref <output_folder>/logs

inverse_spectrogram_n_iter: 1024

tokens: ABCDEFGHIJKLMNOPQRSTUVWXYZ.,!-


encoder: !new:speechbrain.lobes.models.synthesis.deepvoice3.Encoder
  n_vocab: !ref <n_vocab>
  embed_dim: !ref <embed_dim>
  padding_idx: !ref <padding_idx>
  use_speaker_embed: !ref <use_speaker_embed>
  speaker_embed_dim: !ref <speaker_embed_dim>
  dropout: !ref <dropout>
  embedding_weight_std: !ref <embedding_weight_std>
  convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <embed_dim>
      out_channels: !ref <encoder_conv_channels>
      kernel_size: 1
      dilation: 1
      padding: valid
      dropout: 0.
      std_mul: !ref <encoder_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &encoder_conv
      in_channels: !ref <encoder_conv_channels>
      out_channels: !ref <encoder_conv_channels>
      kernel_size: !ref <encoder_conv_kernel_size>
      dilation: !ref <encoder_conv_dilation>
      padding: same
      dropout: !ref <dropout>
      std_mul: !ref <encoder_mid_std_mul>
      residual: True
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 9
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 27
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 9
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 27
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 1
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *encoder_conv
      dilation: 3
      std_mul: !ref <encoder_out_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <encoder_conv_channels>
      out_channels: !ref <embed_dim>
      kernel_size: 1
      padding: valid
      dilation: !ref <encoder_conv_dilation>
      std_mul: !ref <encoder_out_std_mul>
      dropout: !ref <dropout>


decoder: !new:speechbrain.lobes.models.synthesis.deepvoice3.Decoder
  embed_dim: !ref <embed_dim>
  in_dim: !ref <mel_dim>
  r: !ref <outputs_per_step>
  use_speaker_embed: !ref <use_speaker_embed>
  speaker_embed_dim: !ref <speaker_embed_dim>
  dropout: !ref <dropout>
  max_positions: !ref <decoder_max_positions>
  in_channels: !ref <preattention_conv_channels>
  force_monotonic_attention: !ref <force_monotonic_attention>
  query_position_rate: !ref <decoder_query_position_rate>
  key_position_rate: !ref <decoder_key_position_rate>
  preattention:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <mel_dim> * <outputs_per_step>
      out_channels: !ref <preattention_conv_channels>
      kernel_size: 1
      dilation: 1
      padding: valid
      dropout: !ref <dropout>
      std_mul: !ref <preattention_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &decoder_preattention_conv
      in_channels: !ref <preattention_conv_channels>
      out_channels: !ref <preattention_conv_channels>
      kernel_size: !ref <preattention_conv_kernel_size>
      padding: null
      dropout: !ref <dropout>
      std_mul: !ref <preattention_mid_std_mul>
      causal: True
      residual: True
      dilation: 1
      use_speaker_embed: !ref <use_speaker_embed>
      speaker_embed_dim: 16
  convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &decoder_conv
      in_channels: !ref <decoder_conv_channels>
      out_channels: !ref <decoder_conv_channels>
      kernel_size: !ref <decoder_conv_kernel_size>
      dropout: !ref <dropout>
      std_mul: !ref <decoder_low_std_mul>
      causal: True
      residual: False
      dilation: 1
      use_speaker_embed: !ref <use_speaker_embed>
      speaker_embed_dim: 16
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_conv
      dilation: 3
      std_mul: !ref <decoder_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_conv
      dilation: 9
      std_mul: !ref <decoder_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_conv
      dilation: 27
      std_mul: !ref <decoder_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *decoder_conv
      dilation: 1
      std_mul: !ref <decoder_mid_std_mul>
  attention:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionLayer &attention
      conv_channels: !ref <decoder_conv_channels>
      embed_dim: !ref <embed_dim>
      dropout: !ref <dropout>
      window_ahead: !ref <window_ahead>
      window_backward: !ref <window_backward>
      key_projection: !ref <decoder_key_projection>
      value_projection: !ref <decoder_value_projection>
    - null
    - null
    - null
    - null
  output: !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
    in_channels: !ref <decoder_conv_channels>
    out_channels: !ref <mel_dim> * <outputs_per_step>
    kernel_size: 1
    dilation: 1
    padding: valid
    dropout: 0.
    std_mul: !ref <decoder_high_std_mul>


converter: !new:speechbrain.lobes.models.synthesis.deepvoice3.Converter
  use_speaker_embed: !ref <use_speaker_embed>
  in_dim: !ref <converter_in_dim>
  out_dim: !ref <linear_dim>
  dropout: !ref <dropout>
  convolutions:
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <converter_in_dim>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 1
      dilation: 1
      padding: valid
      dropout: 0.
      std_mul: !ref <converter_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.TransposeConvBlock
      in_channels: !ref <converter_in_dim>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 2
      dropout: 0.
      padding: valid
      stride: 2
      std_mul: !ref <converter_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &converter_in_conv
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 3
      dropout: 0.
      causal: False
      residual: True
      dilation: 1
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_in_conv
      dilation: 3
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.TransposeConvBlock
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref <converter_conv_channels>
      kernel_size: 2
      dropout: 0.
      padding: valid
      stride: 2
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_in_conv
      dilation: 1
      std_mul: !ref <converter_in_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_in_conv
      dilation: 3
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock &converter_conv
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref <converter_conv_channels>
      kernel_size: !ref <converter_conv_kernel_size>
      dropout: !ref <dropout>
      causal: False
      residual: True
      dilation: 1
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      dilation: 3
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <converter_conv_channels>
      out_channels: !ref 2 * <converter_conv_channels>
      kernel_size: 1
      padding: valid
      dilation: 1
      dropout: !ref <dropout>
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ReLU
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      in_channels: !ref  <converter_conv_channels_bottom>
      out_channels: !ref <converter_conv_channels_bottom>
      dilation: 1
      residual: True
      std_mul: !ref <converter_mid_std_mul> // 2
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.ConvBlock
      <<: *converter_conv
      in_channels: !ref <converter_conv_channels_bottom>
      out_channels: !ref <converter_conv_channels_bottom>
      dilation: 3
      residual: True
      std_mul: !ref <converter_mid_std_mul>
    - !new:speechbrain.lobes.models.synthesis.deepvoice3.EdgeConvBlock
      in_channels: !ref <converter_conv_channels_bottom>
      out_channels: !ref <linear_dim>
      kernel_size: 1
      padding: valid
      dilation: 1
      dropout: !ref <dropout>
      std_mul: !ref <converter_out_std_mul>


seq2seq: !new:speechbrain.lobes.models.synthesis.deepvoice3.AttentionSeq2Seq
  encoder: !ref <encoder>
  decoder: !ref <decoder>


model: !new:speechbrain.lobes.models.synthesis.deepvoice3.TTSModel
  seq2seq: !ref <seq2seq>
  postnet: !ref <converter>
  mel_dim: !ref <mel_dim>
  linear_dim: !ref <linear_dim>
  use_speaker_embed: !ref <use_speaker_embed>
  speaker_embed_dim: !ref <speaker_embed_dim>
  use_decoder_state_for_postnet_input: !ref <use_decoder_state_for_postnet_input>
  freeze_embedding: !ref <freeze_embedding>
  embed_speakers: !apply:speechbrain.lobes.models.synthesis.deepvoice3.Embedding
    num_embeddings: !ref <n_speakers>
    embedding_dim: !ref <speaker_embed_dim>
    std: !ref <speaker_embedding_weight_std>

model_output_keys:
  - mel
  - linear
  - attention
  - done

pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
  loadables:
    model: !ref <model>
  paths:
    model: !ref <pretrained_path>/model.ckpt

compute_cost: !new:speechbrain.lobes.models.synthesis.deepvoice3.Loss
  linear_dim: !ref <linear_dim>
  downsample_step: !ref <downsample_step>
  outputs_per_step: !ref <outputs_per_step>
  masked_loss_weight: !ref <masked_loss_weight>
  binary_divergence_weight: !ref <binary_divergence_weight>
  priority_freq: !ref <priority_freq>
  priority_freq_weight: !ref <priority_freq_weight>
  sample_rate: !ref <sample_rate>
  guided_attention_sigma: !ref <guided_attention_sigma>

lr_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler
  lr_initial: !ref <lr>
  n_warmup_steps: !ref <lr_warmup_steps>

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <number_of_epochs>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <save_folder>
  recoverables:
    model: !ref <model>
    counter: !ref <epoch_counter>
    lr_annealing: !ref <lr_annealing>

modules:
  model: !ref <model>

datasets:
  train:
    path: !ref <train_data_path>
    loader: !name:datasets.vctk.load
  valid:
    path: !ref <train_data_path>
    loader: !name:datasets.vctk.load

opt_class: !name:torch.optim.Adam
  lr: !ref <lr>

dataloader_options:
  batch_size: !ref <batch_size>
  shuffle: True

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: !ref <train_log>
tensorboard_train_logger: !new:speechbrain.utils.train_logger.TensorboardLogger
  save_dir: !ref <tensorboard_logs>

loggers:
  - !ref <train_logger>
  - !ref <tensorboard_train_logger>

test_frozen_batch: False

speaker_id_encoder: !new:speechbrain.dataio.encoder.CategoricalEncoder

train_pipeline:
  output_keys:
    - text_sequences
    - input_lengths
    - text_positions
    - sig_trimmed
    - speaker_id_enc
  steps:
    - !name:speechbrain.lobes.models.synthesis.dataio.audio_pipeline
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.trim
      takes: sig
      provides: sig_trimmed
      threshold: !ref <trim_threshold>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.text_encoder
      tokens: !ref <tokens>
    - !apply:speechbrain.lobes.models.synthesis.dataio.categorical
      takes: speaker_id
      provides: speaker_id_enc
      encoder: !ref <speaker_id_encoder>

features_pipeline:
  output_keys:
    - text_sequences
    - input_lengths
    - text_positions
    - mel
    - target_lengths
    - frame_positions
    - done
    - linear
    - speaker_id_enc
  steps:
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.resample
      takes: sig_trimmed
      provides: sig_resampled
      orig_freq: !ref <source_sample_rate>
      new_freq: !ref <sample_rate>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.mel_spectrogram
      takes: sig_resampled
      provides: mel_raw
      hop_length: !ref <hop_length>
      n_mels: !ref <mel_dim>
      n_fft: !ref <n_fft>
      power: 1
      sample_rate: !ref <sample_rate>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.normalize_spectrogram
      takes: mel_raw
      provides: mel_norm
      min_level_db: !ref <min_level_db>
      ref_level_db: !ref <ref_level_db>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.pad_spectrogram
      takes: mel_norm
      provides: mel_pad
      outputs_per_step: !ref <outputs_per_step>
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.downsample_spectrogram
      takes: mel_pad
      provides: mel
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.frame_positions
      max_output_len: !ref <max_mel_len> * <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.spectrogram
      takes: sig_resampled
      provides: linear_raw
      n_fft: !ref <n_fft>
      hop_length: !ref <hop_length>
      power: 1
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.normalize_spectrogram
      takes: linear_raw
      provides: linear_norm
      min_level_db: !ref <min_level_db>
      ref_level_db: !ref <ref_level_db>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.pad_spectrogram
      takes: linear_norm
      provides: linear
      outputs_per_step: !ref <outputs_per_step>
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.done
      downsample_step: !ref <mel_downsample_step>
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.target_lengths


encode_pipeline:
  batch: False
  output_keys:
    - text_sequences
    - text_positions
    - input_lengths
  steps:
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.text_encoder
      takes: txt
      tokens: !ref <tokens>


decode_pipeline:
  steps:
    - !apply:speechbrain.lobes.models.synthesis.deepvoice3.denormalize_spectrogram
      takes: linear
      provides: linear_denorm
      min_level_db: !ref <min_level_db>
      ref_level_db: !ref <ref_level_db>
    - !apply:speechbrain.lobes.models.synthesis.dataio.transpose_spectrogram
      takes: linear_denorm
      provides: linear_denorm_flip
    - !apply:speechbrain.lobes.models.synthesis.dataio.inverse_spectrogram
      takes: linear_denorm_flip
      provides: wav
      n_fft: !ref <n_fft>
      n_iter: !ref <inverse_spectrogram_n_iter>
      hop_length: !ref <hop_length>
      power: 1
