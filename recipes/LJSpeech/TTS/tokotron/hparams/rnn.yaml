# ############################################################################
# Model: Tokenized TTS (WhisperSpeech-inspired)
# Authors:  Artem Ploujnikov
# ############################################################################
# Seed needs to be set at top of yaml, before objects with parameters are made

seed: 74443
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref results/rnn/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt

token_model_src: "facebook/encodec_24khz"
vocoder_model: "charactr/vocos-encodec-24khz"

# Data files
data_folder: !PLACEHOLDER # e.g., /path/to/LibriSpeech
# If RIRS_NOISES dir exists in /localscratch/xxx_corpus/RIRS_NOISES
# then data_folder_rirs should be /localscratch/xxx_corpus
# otherwise the dataset will automatically be downloaded
# data_folder_rirs: !ref <data_folder>
prepare_save_folder: !ref <data_folder>/prepared
prepare_archive_path: null
train_annotation: !ref <data_folder>/train.json
valid_annotation: !ref <data_folder>/valid.json
test_annotation: !ref <data_folder>/test.json
progress_folder: !ref <output_folder>/progress
progress_archive: !ref <progress_folder>/progress.tar
progress_current: !ref <progress_folder>/current
progress_meta: !ref <progress_folder>/meta.yaml
num_audio_samples: 32
samples_interval: 5

splits: ["train", "valid", "test"]
split_ratio: [90, 5, 5]


ckpt_interval_minutes: 30 # save checkpoint every N min

# Training parameters
# To make Transformers converge, the global bath size should be large enough.
# The global batch size is computed as batch_size * n_gpus * gradient_accumulation.
# Empirically, we found that this value should be >= 128.
# Please, set your parameters accordingly.
number_of_epochs: 1000
batch_size: 16
grad_accumulation_factor: 1
max_grad_norm: 5.0
sorting: random
num_workers: 4
skip_prep: False
overfit_test: False
overfit_test_sample_count: !ref <batch_size>
overfit_test_epoch_data_count: 1000


# index
pad_index: 0
bos_index: 0

# stages related parameters
lr: 0.001
lr_annealing_mode: epoch
lr_improvement_threshold: 0.02
lr_annealing_factor: 0.8
lr_patient: 0
guided_attention_weight: 50.0
guided_attention_sigma: 0.5
gate_loss_weight: 1.0
gate_threshold: 0.5
gate_loss_beta: 0.2
gate_loss_gamma: 0.01
gate_loss_max_weight: 1.

# Feature parameters
sample_rate: 22050
model_sample_rate: 24000
infer_max_audio_length: 700
debug_infer_max_audio_length: 10

# Label encoder
label_encoder: !new:speechbrain.dataio.encoder.TextEncoder
token_list_file: ./hparams/char_en.txt

# Gate parameters
gate_offset: !apply:speechbrain.nnet.losses.distance_diff_loss_ramp
    beta: !ref <gate_loss_beta>
    gamma: !ref <gate_loss_gamma>
    max_weight: !ref <gate_loss_max_weight>

silence_padding: !ref <gate_offset>


# Token model (pretrained)
token_model: !new:speechbrain.lobes.models.huggingface_transformers.Encodec
    source: !ref <token_model_src>
    save_path: !ref <data_folder>
    flat_embeddings: True

# Dataloader options
train_dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: True
    num_workers: !ref <num_workers>
    collate_fn: !name:speechbrain.dataio.batch.PaddedBatch
        padding_kwargs:
            value: !ref <pad_index>

valid_dataloader_opts:
    batch_size: !ref <batch_size>
    num_workers: !ref <num_workers>
    collate_fn: !name:speechbrain.dataio.batch.PaddedBatch
        padding_kwargs:
            value: !ref <pad_index>

test_dataloader_opts:
    batch_size: 1
    num_workers: !ref <num_workers>
    collate_fn: !name:speechbrain.dataio.batch.PaddedBatch
        padding_kwargs:
            value: !ref <pad_index>

sample_dataloader_opts:
    batch_size: !ref <batch_size>
    num_workers: !ref <num_workers>
    collate_fn: !name:speechbrain.dataio.batch.PaddedBatch
        padding_kwargs:
            value: !ref <pad_index>

extract_features_opts:
    dataloader_opts:
        batch_size: !ref <batch_size>
    token_model: !ref <token_model>
    sample_rate: !ref <sample_rate>
    model_sample_rate: !ref <model_sample_rate>


####################### Model parameters ###########################
# Transformer
## d_model: 512
## nhead: 4
enc_num_layers: 3
enc_rnn_type: gru
enc_hidden_size: 512
enc_bidirectional: True
dec_rnn_type: lstm
dec_hidden_size: 512
dec_num_layers: 3
dec_attn_type: "location"
dec_attn_dim: 512
dec_attn_kernel_size: 100
dec_attn_channels: 10
dec_attn_scaling: 1.0

dropout: 0.2
target_dropout: 0.2
audio_num_tokens: 1024
audio_emb_size: 128
audio_emb_freeze: True
audio_emb_pretrained: True
text_num_tokens: 31
audio_tokens_per_step: 2

############################## models ################################

vocoder: !new:speechbrain.lobes.models.huggingface_transformers.vocos.Vocos
    source: !ref <vocoder_model>
    save_path: !ref <prepare_save_folder>

model: !new:speechbrain.lobes.models.discrete.Tokotron.TokotronRNNModel # yamllint disable-line rule:line-length
    input_num_tokens: !ref <text_num_tokens>
    audio_num_tokens: !ref <audio_num_tokens>
    audio_tokens_per_step: !ref <audio_tokens_per_step>
    enc_rnn_type: !ref <enc_rnn_type>
    enc_hidden_size: !ref <enc_hidden_size>
    enc_num_layers: !ref <enc_num_layers>
    enc_bidirectional: !ref <enc_bidirectional>
    dec_rnn_type: !ref <dec_rnn_type>
    dec_hidden_size: !ref <dec_hidden_size>
    dec_num_layers: !ref <dec_num_layers>
    dec_attn_type: !ref <dec_attn_type>
    dec_attn_dim: !ref <dec_attn_dim>
    dec_attn_kernel_size: !ref <dec_attn_kernel_size>
    dec_attn_channels: !ref <dec_attn_channels>
    dec_attn_scaling: !ref <dec_attn_scaling>
    dropout: !ref <dropout>
    target_dropout: !ref <target_dropout>
    vocoder: !ref <vocoder>
    gate_threshold: !ref <gate_threshold>
    gate_offset: !ref <gate_offset>
    audio_emb_size: !ref <audio_emb_size>
    audio_emb_freeze: !ref <audio_emb_freeze>
    max_audio_length: !ref <infer_max_audio_length>

modules:
    model: !ref <model>
    vocoder: !ref <vocoder>

# define two optimizers here for two-stage training
opt_class: !name:torch.optim.Adam
    lr: !ref <lr>

compute_cost: !new:speechbrain.lobes.models.discrete.Tokotron.TokotronLoss
    seq_cost: !name:speechbrain.nnet.losses.nll_loss
    guided_attention_weight: !ref <guided_attention_weight>
    guided_attention_sigma: !ref <guided_attention_sigma>
    gate_weight: !ref <gate_loss_weight>
    gate_beta: !ref <gate_loss_beta>
    gate_gamma: !ref <gate_loss_gamma>
    gate_max_weight: !ref <gate_loss_max_weight>
    silence_padding: !ref <silence_padding>

lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler
    initial_value: !ref <lr>
    improvement_threshold: !ref <lr_improvement_threshold>
    annealing_factor: !ref <lr_annealing_factor>
    patient: !ref <lr_patient>

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        model: !ref <model>
        lr_annealing: !ref <lr_annealing>
        counter: !ref <epoch_counter>

freezer: !new:speechbrain.dataio.preparation.Freezer
    save_path: !ref <prepare_save_folder>
    archive_path: !ref <prepare_archive_path>

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>

progress_logger: !new:speechbrain.utils.train_logger.ArchiveTrainLogger
    current_path: !ref <progress_current>
    archive_path: !ref <progress_archive>
    meta_path: !ref <progress_meta>
    epoch_counter: !ref <epoch_counter>

progress_report: !new:speechbrain.utils.tts.TTSProgressReport
    logger: !ref <progress_logger>
    sample_rate: !ref <model_sample_rate>
    eos_threshold: !ref <gate_threshold>
