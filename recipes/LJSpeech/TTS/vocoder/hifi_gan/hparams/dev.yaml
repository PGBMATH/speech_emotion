###################################
# Experiment Parameters and setup #
###################################
seed: 321
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref ./results/hifi_gan/<seed>
save_folder: !ref <output_folder>/save
pretrained_path: !ref <save_folder>
train_log: !ref <output_folder>/train_log.txt
epochs: 2000
keep_checkpoint_interval: 20


#################################
# Data files and pre-processing #
#################################
data_folder: ./ #data_folder: !PLACEHOLDER # e.g, /localscratch/ljspeech
train_data_path: /local_disk/arges/jduret/corpus/LJ
# A path to a file with a list of IDs (one per line)
# listing the items from the main data set to be included
# in the training set
train_filter: /local_disk/arges/jduret/corpus/LJ/train_filter.txt
valid_data_path: /local_disk/arges/jduret/corpus/LJ
# A path to a file with a list of IDs (one per line)
# listing the items from the main data set to be included
# in the validation set
valid_filter: /local_disk/arges/jduret/corpus/LJ/valid_filter.txt


################################
# Audio Parameters             #
################################
segment_size: 8192
sample_rate: 22050
hop_length: 256
win_length: 1024
n_mel_channels: 80
n_fft: 1024
n_stft: !ref <n_fft> // 2 + 1
mel_fmin: 0.0
mel_fmax: 8000.0
mel_normalized: null
power: 1.5
dynamic_range_compression: True


################################
# Optimization Hyperparameters #
################################
learning_rate: 0.0002
weight_decay: 0.9999
adam_b1: 0.8
adam_b2: 0.99
grad_clip_thresh: 1.0
batch_size: 32 #minimum 2


################################
# Model Parameters and model   #
################################

# generator params
in_channels: 80
out_channels: 1
resblock_type : "1"
resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
resblock_kernel_sizes: [3, 7, 11]
upsample_kernel_sizes: [16, 16, 4, 4]
upsample_initial_channel: 512
upsample_factors: [8, 8, 2, 2]
inference_padding: 5
cond_channels: 0
conv_pre_weight_norm: True
conv_post_weight_norm: True
conv_post_bias: True

#model
generator: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.HifiganGenerator
    in_channels: !ref <in_channels>
    out_channels: !ref <out_channels>
    resblock_type : !ref <resblock_type>
    resblock_dilation_sizes: !ref <resblock_dilation_sizes>
    resblock_kernel_sizes: !ref <resblock_kernel_sizes>
    upsample_kernel_sizes: !ref <upsample_kernel_sizes>
    upsample_initial_channel: !ref <upsample_initial_channel>
    upsample_factors: !ref <upsample_factors>
    inference_padding: !ref <inference_padding>
    cond_channels: !ref <cond_channels>
    conv_pre_weight_norm: !ref <conv_pre_weight_norm>
    conv_post_weight_norm: !ref <conv_post_weight_norm>
    conv_post_bias: !ref <conv_post_bias>

discriminator: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.HifiganDiscriminator

modules:
    generator: !ref <generator>
    discriminator: !ref <discriminator>

#generator loss
stft_loss: null
mseg_loss: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.MSEGLoss
feat_match_loss: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.MelganFeatureLoss
l1_spec_loss: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.L1SpecLoss
    sample_rate: !ref <sample_rate>
    hop_length: !ref <hop_length>
    win_length: !ref <win_length>
    n_mel_channels: !ref <n_mel_channels>
    n_fft: !ref <n_fft>
    n_stft: !ref <n_fft> // 2 + 1
    mel_fmin: !ref <mel_fmin>
    mel_fmax: null
    mel_normalized: !ref <mel_normalized>
    power: !ref <power>
    dynamic_range_compression: !ref <dynamic_range_compression>

generator_loss: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.GeneratorLoss
    stft_loss: !ref <stft_loss>
    stft_loss_weight: 0
    mseg_loss: !ref <mseg_loss>
    mseg_loss_weight: 1
    feat_match_loss: !ref <feat_match_loss>
    feat_match_loss_weight: 10
    l1_spec_loss: !ref  <l1_spec_loss>
    l1_spec_loss_weight: 45

#discriminator loss
msed_loss: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.MSEDLoss

discriminator_loss: !new:speechbrain.lobes.models.synthesis.hifi_gan.model.DiscriminatorLoss
    msed_loss: !ref <msed_loss>

#optimizer
opt_class_generator: !name:torch.optim.AdamW
    lr: !ref <learning_rate>
    betas: [!ref <adam_b1>, !ref <adam_b2>]

opt_class_discriminator: !name:torch.optim.AdamW
    lr: !ref <learning_rate>
    betas: [!ref <adam_b1>, !ref <adam_b2>]

sch_class_generator: !name:torch.optim.lr_scheduler.ExponentialLR
    gamma: !ref <weight_decay>
    last_epoch: -1

sch_class_discriminator: !name:torch.optim.lr_scheduler.ExponentialLR
    gamma:  !ref <weight_decay>
    last_epoch: -1

#epoch object
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <epochs>

train_logger: !new:speechbrain.utils.train_logger.TensorboardLogger 
    save_dir: !ref <output_folder>/tensorboard

#checkpointer
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        generator: !ref <generator>
        discriminator: !ref <discriminator>
        counter: !ref <epoch_counter>

datasets:
    train:
        path: !ref <train_data_path>
        loader: !name:speechbrain.dataio.datasets.lj.load
        filter: !ref <train_filter>
    valid:
        path: !ref <valid_data_path>
        loader: !name:speechbrain.dataio.datasets.lj.load
        filter: !ref <valid_filter>