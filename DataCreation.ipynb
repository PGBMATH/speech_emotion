{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ded29b0-20e9-44ba-8ae5-e2c0f0d9f043",
   "metadata": {},
   "source": [
    "## Creation of Multi-Speaker Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8986d4a-823e-41a3-bf0c-78d22e1e8e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/matteo/.local/share/jupyter/runtime/kernel-099736a4-f4c5-45da-bd54-4641a530ccdc.json', {'debug': False, 'debug_batches': 2, 'debug_epochs': 2, 'device': 'cuda:0', 'data_parallel_count': -1, 'data_parallel_backend': False, 'distributed_launch': False, 'distributed_backend': 'nccl', 'auto_mix_prec': False, 'noprogressbar': False}, '-f')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "from speechbrain.dataio.dataio import read_audio, write_audio\n",
    "import speechbrain as sb\n",
    "os.chdir(\"/home/matteo/projects/speechbrain/\")\n",
    "\n",
    "# CLI:\n",
    "data_folder = sb.parse_arguments(sys.argv[1:])\n",
    "print(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c178c5c-9253-4f39-b1bb-05bc167d03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/matteo/projects/data/5s-LibriSpeech/\"\n",
    "AUDIO_FOLDERS = [\"dev-clean\", \"test-clean\", \"train-clean-100\"]\n",
    "SAMPLING_RATE = 16000 #hz\n",
    "MAX_DURATION = 5 #seconds\n",
    "MAX_SAMPLES = MAX_DURATION * SAMPLING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4e58ba5-397f-44e2-bc0c-7b6da3188ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80000])\n",
      "5.0 second sample\n"
     ]
    }
   ],
   "source": [
    "xs_speech = read_audio('/home/matteo/projects/data/5s-LibriSpeech/dev-clean/8842-304647-0012-5s-w-padding.flac')\n",
    "xs_speech = xs_speech.unsqueeze(0) # [batch, time, channels]\n",
    "print(xs_speech.size())\n",
    "duration = xs_speech.size()[1] / SAMPLING_RATE\n",
    "print(f'{duration} second sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d409f1e4-517e-4f0d-8abc-00bb4782272c",
   "metadata": {},
   "source": [
    "## Crop all samples to max 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4c25bf-acf1-4fd4-9efb-6a764da5299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of flac audio files in LibriSpeech\n",
    "audio_files = [] \n",
    "for folder in AUDIO_FOLDERS:\n",
    "    audio_files.append(glob.glob(f\"/home/matteo/projects/data/5s-LibriSpeech/{folder}/*.flac\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "064322ce-3331-49b3-bf0c-9e5371517a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev-clean unique speakers = 40\n",
      "test-clean unique speakers = 40\n",
      "train-clean-100 unique speakers = 251\n"
     ]
    }
   ],
   "source": [
    "# Get list of unique speaker ids\n",
    "unique_speakers = [[], [], []]\n",
    "for folder_idx in range(3):\n",
    "    for path in audio_files[folder_idx]:\n",
    "        unique_speakers[folder_idx].append(path.split('/')[-1].split('-')[0])    \n",
    "    unique_speakers[folder_idx] = list(set(unique_speakers[folder_idx]))\n",
    "    print(f\"{AUDIO_FOLDERS[folder_idx]} unique speakers = {len(unique_speakers[folder_idx])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "780bd91f-e41c-4e3a-bce6-1859343c75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crop all samples to max(original_duration, 5)\n",
    "# for i in range(0,3):\n",
    "#     print(f\"Shortening and adding padding to all {AUDIO_FOLDERS[i].split('/')[-1]} samples to create 5s total duration\")\n",
    "#     for recording in audio_files[i]:\n",
    "#         xs_speech = read_audio(recording)\n",
    "#         temp = xs_speech.unsqueeze(0)[0][:MAX_SAMPLES] # [batch, time, channels]\n",
    "#         write_audio(recording[:-5] + \"-5s.flac\", temp, 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a434d38-1f71-41f0-bed0-c46d602748bc",
   "metadata": {},
   "source": [
    "## Add padding to make all clips exactly 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca8ef643-123c-4bf1-a5c3-fc9f17e632c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding padding to all dev-clean samples to create 5s total duration\n",
      "Adding padding to all test-clean samples to create 5s total duration\n",
      "Adding padding to all train-clean-100 samples to create 5s total duration\n"
     ]
    }
   ],
   "source": [
    "# audio_files = [] \n",
    "# for folder in AUDIO_FOLDERS:\n",
    "#     audio_files.append(glob.glob(f\"/home/matteo/projects/data/5s-LibriSpeech/{folder}/*.flac\"))\n",
    "\n",
    "# for i in range(0,3):\n",
    "#     print(f\"Adding padding to all {AUDIO_FOLDERS[i].split('/')[-1]} samples to create 5s total duration\")\n",
    "#     for recording in audio_files[i]:\n",
    "        \n",
    "#         # Read file\n",
    "#         xs_speech = read_audio(recording)\n",
    "#         xs_speech = xs_speech.unsqueeze(0)\n",
    "        \n",
    "#         # Add padding\n",
    "#         padding_tensor = torch.zeros(size=(1, MAX_SAMPLES))\n",
    "#         padding_tensor[0,:xs_speech.size()[1]] = xs_speech\n",
    "        \n",
    "#         # Write file\n",
    "#         write_audio(recording[:-5] + \"-w-padding.flac\", padding_tensor.reshape(-1), 16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca694d52-8325-4afe-9f0d-da32f7a133c1",
   "metadata": {},
   "source": [
    "## Combine 5s audio clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e4955a4-6355-492a-8d69-9537ae1db8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dev-clean random mixtures (1/3)\n",
      "Creating dev-clean random mixtures (2/3)\n",
      "Creating dev-clean random mixtures (3/3)\n",
      "{'1': 1535, '2': 1664, '3': 1659, '4': 1631, '5': 1620}\n",
      "Creating test-clean random mixtures (1/3)\n",
      "Creating test-clean random mixtures (2/3)\n",
      "Creating test-clean random mixtures (3/3)\n",
      "{'1': 1546, '2': 1613, '3': 1537, '4': 1596, '5': 1568}\n",
      "Creating train-clean-100 random mixtures (1/3)\n",
      "Creating train-clean-100 random mixtures (2/3)\n",
      "Creating train-clean-100 random mixtures (3/3)\n",
      "{'1': 17144, '2': 17143, '3': 17119, '4': 17104, '5': 17107}\n"
     ]
    }
   ],
   "source": [
    "# Make 1 to 5 overlap folders to store intersecting audio\n",
    "for folder in AUDIO_FOLDERS:\n",
    "    for i in range(1, 6):\n",
    "        new_folder_path = os.path.join(DATADIR, folder + \"/\", f\"{i}-speaker\")\n",
    "        if os.path.exists(new_folder_path):\n",
    "            shutil.rmtree(new_folder_path)\n",
    "        os.makedirs(new_folder_path)\n",
    "\n",
    "# Get random number of unique speaker audio files and combine them (3 times per point, therefore augmenting data 3x)\n",
    "for folder_id in range(0, 3):\n",
    "    nb_speakers_log = {\"1\": 0, \"2\": 0, \"3\": 0, \"4\": 0, \"5\": 0}\n",
    "    for iteration in range(0, 3):\n",
    "        print(f\"Creating {AUDIO_FOLDERS[folder_id]} random mixtures ({iteration+1}/3)\")\n",
    "        for path in audio_files[folder_id]:\n",
    "            mix_files = []\n",
    "            nb_speakers = random.randint(1, 5)\n",
    "            nb_speakers_log[str(nb_speakers)] += 1 # Keeping a count of the number of 1-5 speaker signals created.\n",
    "            speaker_indices = random.sample(unique_speakers[folder_id], nb_speakers)\n",
    "\n",
    "            # Get n unique files.\n",
    "            for speaker_idx in speaker_indices:\n",
    "                samples_w_given_speaker = [audio for audio in audio_files[folder_id] if audio.split('/')[-1].split('-')[0] == speaker_idx]\n",
    "                mix_files.append(random.choice(samples_w_given_speaker))\n",
    "\n",
    "            # Read and combine n unique files.\n",
    "            out = torch.zeros(size=(1, MAX_SAMPLES))\n",
    "            for flac in mix_files:\n",
    "#                 random_amplitude = random.uniform(0.5, 1)\n",
    "                signal = read_audio(flac)\n",
    "                out += signal/torch.norm(signal)\n",
    "\n",
    "            # Normalize mixture\n",
    "#             amp_final = random.uniform(0.5, 1)\n",
    "#             mix_final = amp_final*out/abs(out)\n",
    "            mix_final = out/torch.norm(out)\n",
    "                \n",
    "            # Output in appropriate folder\n",
    "            mixture_name = \"-\".join(speaker_indices) + \"-id-\" + str(random.randint(0, 1000000)) + \".flac\"\n",
    "            write_audio(f'/home/matteo/projects/data/5s-LibriSpeech/{AUDIO_FOLDERS[folder_id]}/{nb_speakers}-speaker/{mixture_name}', out.reshape(-1), 16000)\n",
    "            \n",
    "    print(\"Speaker mixture counts: \", nb_speakers_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd3c53-b1f7-4e90-832b-1ac9381997b7",
   "metadata": {},
   "source": [
    "## Issue with normalization of mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ea2e3b3c-4f89-4b27-9e9b-b27c2ae86c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize mixture\n",
    "signal1 = read_audio(\"/home/matteo/projects/data/5s-LibriSpeech/dev-clean/8842-304647-0013-5s-w-padding.flac\")\n",
    "signal2 = read_audio(\"/home/matteo/projects/data/5s-LibriSpeech/dev-clean/8297-275154-0009-5s-w-padding.flac\")\n",
    "\n",
    "signal1 /= torch.norm(signal1)\n",
    "signal2 /= torch.norm(signal2)\n",
    "\n",
    "write_audio(f'/home/matteo/Desktop/normalized-signal-1.flac', signal1.reshape(-1), 16000)\n",
    "write_audio(f'/home/matteo/Desktop/normalized-signal-2.flac', signal2.reshape(-1), 16000)\n",
    "\n",
    "mix = signal1 + signal2\n",
    "mix_final = mix / torch.norm(mix)\n",
    "write_audio(f'/home/matteo/Desktop/normalized-mix.flac', mix_final.reshape(-1), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "590b4bc8-7851-452f-94b5-aedf797f8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0623)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/torch.norm(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a68e6-1899-485f-9e41-dd404e36d5e7",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8ae30bb5-5923-4097-a0f5-a39aa02ded1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0280, 0.1364, 0.3073, 0.4672, 0.1843, 0.1835, 0.4672, 0.0245, 0.0334,\n",
       "         0.1008, 0.3579, 0.4835, 0.3541, 0.2426, 0.4206, 0.3084, 0.5155, 0.0537,\n",
       "         0.1480, 0.3339, 0.2869, 0.3941, 0.2363, 0.0438, 0.3016, 0.2383, 0.3233,\n",
       "         0.2327, 0.4076, 0.0942, 0.4946, 0.4827, 0.4047, 0.2229, 0.0310, 0.2693,\n",
       "         0.2025, 0.5305, 0.1510, 0.0423, 0.3198, 0.1297, 0.5534, 0.3578, 0.3174,\n",
       "         0.4060, 0.2083, 0.4383, 0.1741, 0.4602, 0.1408, 0.5316, 0.3169, 0.1578,\n",
       "         0.2806, 0.5180, 0.1265, 0.2656, 0.2718, 0.4946, 0.5432, 0.2318, 0.5598,\n",
       "         0.1045, 0.3467, 0.1852, 0.5656, 0.1614, 0.0882, 0.3081, 0.1189, 0.5550,\n",
       "         0.2479, 0.3955, 0.4809, 0.4425, 0.4321, 0.2376, 0.3858, 0.0313, 0.0907,\n",
       "         0.1604, 0.1318, 0.4905, 0.0131, 0.2096, 0.5452, 0.2597, 0.4411, 0.2101]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_amplitude = random.uniform(0.5, 1)\n",
    "random_amplitude*abs(-torch.rand(size=(1, 90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06c352-d579-4447-9f3e-a51c771f36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overlapping audio of 2 speakers\n",
    "\n",
    "# file1 = read_audio('/home/matteo/projects/data/5s-LibriSpeech/dev-clean/8842-304647-0012-5s-w-padding.flac')\n",
    "# file2 = read_audio('/home/matteo/projects/data/5s-LibriSpeech/dev-clean/5895-34622-0016-5s-w-padding.flac')\n",
    "# write_audio(\"/home/matteo/Desktop/mix.flac\", (file1+file2).reshape(-1), 16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
